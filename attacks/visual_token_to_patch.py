#!/usr/bin/env python3
"""
Experiment 1: Pixel-level Verification
======================================
å°†32ä¸ªVISUAL token IDsè§£ç ä¸ºadversarial image patch

ç›®æ ‡ï¼š
1. è¯æ˜VISUAL tokens = adversarial image patchesï¼ˆå¯ä»¥ä½œä¸ºå›¾åƒä¸Šä¼ ï¼‰
2. éªŒè¯è¿™æ˜¯çœŸæ­£çš„black-box attackï¼ˆä¸éœ€è¦token ID APIï¼‰
3. æµ‹è¯•re-encodeçš„tokensæ˜¯å¦ä»ç„¶æœ‰æ•ˆ

æµç¨‹ï¼š
Visual Token IDs â†’ VQ-GAN Decode â†’ Adversarial Patch (PNG)
                                           â†“
                    VQ-GAN Encode â†’ Token IDs' â†’ Test Attack
"""

import sys
sys.path.insert(0, "/root/autodl-tmp/thinking-with-generated-images/transformers/src")
sys.path.insert(0, "/root/autodl-tmp/thinking-with-generated-images")

import torch
import json
import os
from transformers import ChameleonConfig, ChameleonProcessor, ChameleonForConditionalGenerationWithCFG
from transformers.image_transforms import to_pil_image
from PIL import Image
import numpy as np

def decode_visual_tokens_to_patch(model, processor, visual_token_ids):
    """
    å°†32ä¸ªvisual tokensè§£ç ä¸ºadversarial patch

    æ³¨æ„ï¼š32 tokens = 32x8x8åƒç´ å—ï¼ˆä½¿ç”¨VQ-GANçš„8x8 patch sizeï¼‰
          ä½†æˆ‘ä»¬éœ€è¦å°†å…¶æ’åˆ—æˆå›¾åƒ
    """
    print("="*60)
    print("PHASE 1: DECODE VISUAL TOKENS TO IMAGE PATCH")
    print("="*60)
    print()

    print(f"Visual token IDs: {visual_token_ids[:10]}... ({len(visual_token_ids)} total)")

    # æ£€æŸ¥tokenèŒƒå›´
    assert all(4 <= tid <= 8195 for tid in visual_token_ids), "Some tokens are not VISUAL tokens!"
    print(f"âœ“ All {len(visual_token_ids)} tokens are VISUAL tokens (4-8195)")
    print()

    # Chameleonçš„å›¾åƒtokenæ˜¯1024ä¸ªï¼ˆ32x32 gridï¼Œæ¯ä¸ª8x8åƒç´ ï¼‰
    # ä½†æˆ‘ä»¬åªæœ‰32ä¸ªtokensï¼Œæ‰€ä»¥éœ€è¦paddingæˆ–è€…åˆ›å»ºä¸€ä¸ªå°å›¾åƒ

    # ç­–ç•¥ï¼šåˆ›å»º32x32 token gridï¼Œä½†åªç”¨å‰32ä¸ªä½ç½®ï¼Œå…¶ä½™å¡«å……ä¸ºblack (token 4)
    BLACK_TOKEN = 4  # å‡è®¾token 4æ˜¯é»‘è‰²æˆ–neutral

    # æ„é€ 1024 tokenåºåˆ—
    full_tokens = [BLACK_TOKEN] * 1024
    full_tokens[:32] = visual_token_ids

    print(f"Creating 32x32 token grid (1024 tokens total)")
    print(f"  - First 32 positions: adversarial tokens")
    print(f"  - Remaining 992 positions: black/neutral (token {BLACK_TOKEN})")
    print()

    # è§£ç 
    token_tensor = torch.tensor([full_tokens], device="cuda", dtype=torch.long)

    print("Decoding via VQ-GAN...")
    with torch.no_grad():
        pixel_values = model.model.decode_image_tokens(token_tensor)
        images = processor.postprocess_pixel_values(pixel_values)

    patch_image = to_pil_image(images[0].detach().cpu())

    print(f"âœ“ Decoded to image: {patch_image.size}")
    print()

    return patch_image, full_tokens

def encode_patch_to_tokens(model, processor, patch_image):
    """
    å°†adversarial patché‡æ–°ç¼–ç ä¸ºtokens
    """
    print("="*60)
    print("PHASE 2: RE-ENCODE IMAGE PATCH TO TOKENS")
    print("="*60)
    print()

    print(f"Input image size: {patch_image.size}")

    # é¢„å¤„ç†å›¾åƒ
    pixel_values = processor.image_processor(patch_image, return_tensors="pt")['pixel_values']
    pixel_values = pixel_values.to(device="cuda", dtype=torch.bfloat16)

    print(f"Pixel values shape: {pixel_values.shape}")

    # ç¼–ç 
    print("Encoding via VQ-GAN...")
    with torch.no_grad():
        encoded_output = model.model.vqmodel.encode(pixel_values)
        # encodeè¿”å›tuple: (quantized, indices)
        if isinstance(encoded_output, tuple):
            image_tokens = encoded_output[1]  # indices
        else:
            image_tokens = encoded_output

    print(f"  Image tokens shape: {image_tokens.shape}")
    print(f"  Image tokens dtype: {image_tokens.dtype}")

    # Convert to list
    if image_tokens.dim() == 0:
        reencoded_ids = [image_tokens.item()]
    elif image_tokens.dim() == 1:
        reencoded_ids = image_tokens.cpu().tolist()
    else:
        # Flatten if needed
        reencoded_ids = image_tokens.flatten().cpu().tolist()

    print(f"âœ“ Re-encoded to {len(reencoded_ids)} tokens")
    print(f"  Token range: [{min(reencoded_ids)}, {max(reencoded_ids)}]")
    print()

    return reencoded_ids

def test_reencoded_attack(model, processor, reencoded_ids, instruction, victim_prompt):
    """
    æµ‹è¯•re-encoded tokensæ˜¯å¦ä»ç„¶æœ‰æ•ˆ
    """
    print("="*60)
    print("PHASE 3: TEST RE-ENCODED ATTACK")
    print("="*60)
    print()

    BOI = 8197
    EOI = 8196

    # åªä½¿ç”¨å‰32ä¸ªre-encoded tokensï¼ˆå¯¹åº”æˆ‘ä»¬çš„adversarial patchï¼‰
    adversarial_tokens = reencoded_ids[:32]

    print(f"Using first 32 re-encoded tokens as adversarial prefix")
    print(f"  Tokens: {adversarial_tokens[:10]}...")
    print()

    # Tokenize instruction and victim
    instruction_ids = processor.tokenizer(instruction, add_special_tokens=False)['input_ids']
    victim_ids = processor.tokenizer(victim_prompt, add_special_tokens=False)['input_ids']

    # Construct input: instruction + adversarial_tokens + victim + [BOI]
    input_ids = instruction_ids + adversarial_tokens + victim_ids + [BOI]
    input_tensor = torch.tensor([input_ids], dtype=torch.long, device="cuda")

    print(f"Input structure:")
    print(f"  - Instruction: {len(instruction_ids)} tokens")
    print(f"  - Adversarial patch: {len(adversarial_tokens)} tokens")
    print(f"  - Victim: {len(victim_ids)} tokens")
    print(f"  - Total: {len(input_ids)} tokens")
    print()

    print("Generating with re-encoded adversarial patch...")
    with torch.no_grad():
        generated_ids = model.generate(
            input_ids=input_tensor,
            max_new_tokens=1050,
            do_sample=False,
            bos_token_id=BOI,
            eos_token_id=EOI,
            pad_token_id=processor.tokenizer.pad_token_id,
        )

    new_tokens = generated_ids[0, len(input_ids):]

    # Split image and text
    try:
        eoi_idx = (new_tokens == EOI).nonzero(as_tuple=True)[0][0].item()
        image_tokens = new_tokens[:eoi_idx].cpu().tolist()
        text_tokens = new_tokens[eoi_idx+1:]
    except:
        image_tokens = new_tokens[:1024].cpu().tolist()
        text_tokens = []

    generated_text = processor.tokenizer.decode(text_tokens, skip_special_tokens=True) if len(text_tokens) > 0 else ""

    print(f"âœ“ Generated {len(image_tokens)} image tokens")
    print(f"âœ“ Generated text: \"{generated_text}\"")
    print()

    # Evaluation
    print("="*60)
    print("ATTACK EVALUATION")
    print("="*60)
    print()

    success = False
    if "dog" in generated_text.lower() and "cat" not in generated_text.lower():
        print("ğŸ¯ SUCCESS! Re-encoded adversarial patch still works!")
        print("   This proves VISUAL tokens = uploadable adversarial patches")
        success = True
    elif "cat" in generated_text.lower():
        print("âŒ FAILED: Attack signal lost during re-encoding")
    else:
        print("âš ï¸  PARTIAL: Need to check the image manually")

    print()

    return {
        'reencoded_tokens': adversarial_tokens,
        'generated_text': generated_text,
        'image_tokens': image_tokens,
        'success': success
    }

def compare_tokens(original_ids, reencoded_ids):
    """
    æ¯”è¾ƒåŸå§‹tokenså’Œre-encoded tokens
    """
    print("="*60)
    print("TOKEN COMPARISON")
    print("="*60)
    print()

    # åªæ¯”è¾ƒå‰32ä¸ª
    orig_32 = original_ids[:32]
    reen_32 = reencoded_ids[:32]

    matches = sum(1 for o, r in zip(orig_32, reen_32) if o == r)
    match_rate = matches / 32

    print(f"Original tokens (first 32): {orig_32[:10]}...")
    print(f"Re-encoded tokens (first 32): {reen_32[:10]}...")
    print()
    print(f"Exact matches: {matches}/32 ({match_rate*100:.1f}%)")
    print()

    if match_rate > 0.9:
        print("âœ“ High fidelity: VQ-GAN encode-decode is nearly lossless")
    elif match_rate > 0.5:
        print("âš ï¸ Moderate fidelity: Some quantization loss")
    else:
        print("âŒ Low fidelity: Significant information loss")

    print()

    return match_rate

def main():
    print("="*60)
    print("EXPERIMENT 1: PIXEL-LEVEL VERIFICATION")
    print("="*60)
    print()
    print("Research Question:")
    print("  Can VISUAL tokens be decoded to an adversarial image patch")
    print("  and uploaded as a TRUE black-box attack?")
    print()

    # Load model
    model_path = "twgi-critique-anole-7b"
    print(f"Loading model: {model_path}")

    config = ChameleonConfig.from_pretrained(model_path)
    config._attn_implementation = "eager"
    processor = ChameleonProcessor.from_pretrained(model_path)
    model = ChameleonForConditionalGenerationWithCFG.from_pretrained(
        model_path, config=config, torch_dtype=torch.bfloat16
    ).to("cuda")
    model.eval()
    model.setup_cfg(cfg_config="no")

    print("âœ“ Model loaded")
    print()

    # Load successful 32-token attack
    prefix_file = "outputs/reproducibility/prefix_32_run2/hybrid_discrete_prefix.json"
    print(f"Loading successful attack prefix: {prefix_file}")

    with open(prefix_file, 'r') as f:
        prefix_data = json.load(f)

    visual_token_ids = prefix_data['visual_discrete_ids']
    instruction = prefix_data['instruction_text']

    print(f"âœ“ Loaded {len(visual_token_ids)} visual tokens")
    print(f"  Instruction: {instruction}")
    print()

    # Phase 1: Decode to patch
    patch_image, full_token_sequence = decode_visual_tokens_to_patch(model, processor, visual_token_ids)

    # Save patch
    output_dir = "outputs/visual_patch_experiment"
    os.makedirs(output_dir, exist_ok=True)

    patch_path = os.path.join(output_dir, "adversarial_patch.png")
    patch_image.save(patch_path)
    print(f"âœ“ Adversarial patch saved: {patch_path}")
    print()

    # Phase 2: Re-encode patch
    reencoded_ids = encode_patch_to_tokens(model, processor, patch_image)

    # Compare tokens
    match_rate = compare_tokens(full_token_sequence, reencoded_ids)

    # Phase 3: Test attack with re-encoded tokens
    victim_prompt = "a photo of a cat"
    result = test_reencoded_attack(model, processor, reencoded_ids, instruction, victim_prompt)

    # Save re-encoded results
    result_data = {
        'original_visual_tokens': visual_token_ids,
        'reencoded_tokens_32': result['reencoded_tokens'],
        'full_reencoded_tokens_1024': reencoded_ids,
        'token_match_rate': match_rate,
        'generated_text': result['generated_text'],
        'image_tokens': result['image_tokens'],
        'success': result['success']
    }

    result_file = os.path.join(output_dir, "reencoded_attack_results.json")
    with open(result_file, 'w') as f:
        json.dump(result_data, f, indent=2)

    print(f"âœ“ Results saved: {result_file}")
    print()

    # Decode generated image
    if len(result['image_tokens']) == 1024:
        print("Decoding generated image...")
        token_tensor = torch.tensor([result['image_tokens']], device="cuda", dtype=torch.long)
        with torch.no_grad():
            pixel_values = model.model.decode_image_tokens(token_tensor)
            images = processor.postprocess_pixel_values(pixel_values)

        generated_image = to_pil_image(images[0].detach().cpu())
        generated_path = os.path.join(output_dir, "reencoded_generated_image.png")
        generated_image.save(generated_path)
        print(f"âœ“ Generated image saved: {generated_path}")
        print()

    # Final summary
    print("="*60)
    print("EXPERIMENT COMPLETE")
    print("="*60)
    print()

    if result['success']:
        print("ğŸ‰ BREAKTHROUGH: Visual tokens ARE adversarial image patches!")
        print()
        print("Key findings:")
        print(f"  1. Visual tokens decoded to uploadable PNG image")
        print(f"  2. Re-encoding preserved {match_rate*100:.1f}% of tokens")
        print(f"  3. Re-encoded patch still triggers dog generation")
        print()
        print("Implication: TRUE black-box attack via image upload!")
    else:
        print("ğŸ“Š Results:")
        print(f"  - Token match rate: {match_rate*100:.1f}%")
        print(f"  - Generated text: \"{result['generated_text']}\"")
        print(f"  - Attack success: {'Yes' if result['success'] else 'No'}")
        print()
        print("The adversarial patch exists, but may need refinement.")

    print()

if __name__ == "__main__":
    main()
